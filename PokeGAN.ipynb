{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PokeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"kodlak15/pokegan\" on https://jovian.ai/\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/kodlak15/pokegan\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/kodlak15/pokegan'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "import jovian\n",
    "jovian.commit(filename=\"PokeGAN.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from os import path\n",
    "from utils import *\n",
    "from device_mgmt import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "img_dir = format_path(join(root_dir, \"images\"))\n",
    "train_dir = format_path(join(img_dir, \"train-images\"))\n",
    "fake_dir = join(root_dir, \"fakes\")\n",
    "weights_dir = join(root_dir, \"weights\")\n",
    "history_dir = join(root_dir, \"history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from PokeScraper import get_images\n",
    "get_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from dataset import PokemonDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 905 images in the train dataset\n"
     ]
    }
   ],
   "source": [
    "train_stats = [0.8577, 0.8482, 0.8384], [0.0579, 0.0565, 0.0608]\n",
    "img_size = 128\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Lambda(lambda img: transform_image(img)),\n",
    "    T.ColorJitter(brightness=0, contrast=0, saturation=(1.0, 1.5), hue=(-0.15, 0.15)),\n",
    "    T.Resize(img_size),\n",
    "    T.CenterCrop(img_size),\n",
    "    T.RandomHorizontalFlip(0.2),\n",
    "    T.RandomRotation(3, fill=0),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# T.Normalize(*train_stats)\n",
    "\n",
    "train_ds = PokemonDataset(train_dir, transform=train_transform)\n",
    "print(f\"There are {len(train_ds)} images in the train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch tensor shape: torch.Size([64, 3, 128, 128])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "show_images() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/cody/Programming/PokeGAN/PokeGAN.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cody/Programming/PokeGAN/PokeGAN.ipynb#ch0000011?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch tensor shape: \u001b[39m\u001b[39m{\u001b[39;00mbatch\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cody/Programming/PokeGAN/PokeGAN.ipynb#ch0000011?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cody/Programming/PokeGAN/PokeGAN.ipynb#ch0000011?line=4'>5</a>\u001b[0m show_images(train_dl, train_stats)\n",
      "File \u001b[0;32m~/anaconda3/envs/Jovian/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: show_images() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print(f\"Batch tensor shape: {batch.shape}\")\n",
    "    break\n",
    "\n",
    "show_images(train_dl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "print(f\"Current device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "clear_cache_and_get_info(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from models import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = to_device(Discriminator(), device)\n",
    "G = to_device(Generator(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How training works: \n",
    "- The discriminator is trained before the generator. It computes the scores (% predicted to be real) and loss values for real and fake images based on predictions made by the generator. \n",
    "- The generator is trained second. It creates fake images, then feeds them to the (new) discriminator, returning a loss value. \n",
    "- Since the discriminator is trained using the generator from the previous epoch, you can sometimes infer how well the fake images will score by the generator loss from the previous epoch. \n",
    "    - ie: if the generator loss last epoch was exceptionally low, you can generally expect the discriminator to struggle more to correctly label the image fake.\n",
    "- The discriminator eventually regains the upper hand, challenging the generator to create better fakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = fit(D, G, train_dl, epochs, lr, device, start_idx=len(os.listdir(fake_dir))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 128\n",
    "x = torch.randn(1, latent_size, 1, 1, device=\"cpu\")\n",
    "G = to_device(G, device=\"cpu\")\n",
    "fake = G(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    show_images(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('Jovian')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e5a82fdc887cbdaa189a2800f151fe693184309a9dd3cdcdd49c9afd53da1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
